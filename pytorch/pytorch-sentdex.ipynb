{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Introduction\n",
    " \n",
    "---\n",
    "\n",
    "Running numpy on GPU, with some nice helper functions.\n",
    "\n",
    "GPU responsible for small calculations, have a lot more cores than CPU\n",
    "\n",
    "CPU responsible for large calcultions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 5.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.Tensor([3,5])\n",
    "y = torch.Tensor([2,1])\n",
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros([3,1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9406, 0.7457, 0.2727, 0.8933, 0.9393],\n",
       "        [0.4339, 0.1879, 0.1300, 0.6488, 0.8180]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape: flatten the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9406, 0.7457, 0.2727, 0.8933, 0.9393, 0.4339, 0.1879, 0.1300, 0.6488,\n",
       "         0.8180]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.view([1,10])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Data\n",
    "---\n",
    "\n",
    "- Is the data machine-learnable?\n",
    "- 90% of time is spent on data collection\n",
    "- Vision is the main interest\n",
    "\n",
    "- Training and testing data sets\n",
    "\n",
    "> hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST: hand-drawn digits from 0 to 9\n",
    "- 28 x 28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test = datasets.MNIST(\"\", train=False, download=True, \n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Use batch_size, instead of passing data in one go\n",
    "- because data cannot fit into GPU\n",
    "- and to hope that the data will generalise\n",
    "- batch_size between 8 and 64\n",
    "---\n",
    "- shuffle: to make neural network generalise/ learn general rules instead of quicker routes\n",
    "\n",
    "16:00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([1, 8, 0, 2, 5, 7, 2, 3, 4, 9])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# x is the image\n",
    "# y is the label\n",
    "\n",
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1230a79d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reshape the tensor to 28 by 28\n",
    "\n",
    "plt.imshow(data[0][3].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing dataset\n",
    "---\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "# printing how balanced the dataset is\n",
    "\n",
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0 }\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total +=1\n",
    "        \n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
